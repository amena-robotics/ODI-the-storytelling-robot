# Emotion recognition & contemporary neuroscience

Standard computer vision approaches (OpenCV Haar Cascade) classify emotions as **discrete categories**: happy, sad, angry, neutral.

However, **Lisa Feldman Barrett's theory of constructed emotion** challenges this model:

### Constructed emotion theory

Emotions are not fixed, hardwired expressions. Instead:
- Brain **predicts** emotional states based on context
- Facial expressions are ambiguous (same face = different emotions in different contexts)
- No universal emotion signatures across cultures
- Emotions are culturally constructed & socially negotiated

## Why this matters for ODI?

**Problem**: If facial expressions don't reliably indicate emotions, our emotion-based storytelling adaptation risks:
- Misinterpreting audience intent
- Selecting inappropriate stories
- Reinforcing cultural stereotypes
- False confidence in AI predictions

---

## Future direction: allostasis

Moving forward, we're exploring **allostasis** (predictive body regulation) as a better theoretical foundation for:
Allostasis explains how the body **predicts** and **maintains** stability.

1. **Understanding emotion in social robotics** 
2. **Designing adaptive systems** 
3. **Neural interfaces** â€“ Allostasis-based metrics for human-computer synchrony
   
---

## Critical takeaway

**Our system is honest about uncertainty.** We don't claim to recognise "true" emotions, we acknowledge the neuroscientific evidence that emotions are constructed, contextual and socially embedded.

This honesty is essential for culturally-sensitive storytelling, especially when preserving indigenous narratives.

---

## References

- Barrett, L. F. (2017). *How Emotions Are Made*. Houghton Mifflin Harcourt.
- Feldman Barrett, L., & Simmons, W. K. (2015). "Interoceptive Predictions in the Brain." *Nature Reviews Neuroscience*, 16(7), 419-429.
- [Your ICSR 2026 submission reference]

---

For system architecture, see [ARCHITECTURE.md](ARCHITECTURE.md).

---
